import os
import random
import subprocess
from moviepy.editor import ImageClip, VideoFileClip, concatenate_videoclips
from pydub import AudioSegment
import requests

# === Cáº¤U HÃŒNH ===
DURATION_PER_IMAGE = 3
TEMP_VIDEO = "temp.mp4"
SUB_FILE = "subtitles.srt"
AUDIO_FILE = "voice.mp3"
FINAL_VIDEO = "final_output.mp4"

# === VOICE Báº°NG API ELEVENLABS ===
def create_voice_with_elevenlabs(text, output_file, api_key, voice_id="EXAVITQu4vr4xnSDxMaL"):  # Rachel
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"

    headers = {
        "xi-api-key": api_key,
        "Content-Type": "application/json"
    }

    payload = {
        "text": text,
        "model_id": "eleven_turbo_v2_5",
        "voice_settings": {
            "stability": 0.5,
            "similarity_boost": 0.75
        }
    }

    response = requests.post(url, headers=headers, json=payload)

    if response.status_code == 200:
        with open(output_file, "wb") as f:
            f.write(response.content)
        print(f"âœ… ÄÃ£ lÆ°u voice vÃ o {output_file}")
    else:
        print(f"âŒ Lá»—i táº¡o voice: {response.status_code}")
        print(response.text)
        exit()

# === TÃCH VÄ‚N Báº¢N ===
def split_text_to_words(text):
    return text.strip().split()

# === Táº O PHá»¤ Äá»€ Tá»ªNG Tá»ª ===
def format_time_ms(ms):
    s, ms = divmod(ms, 1000)
    m, s = divmod(s, 60)
    h, m = divmod(m, 60)
    return f"{int(h):02d}:{int(m):02d}:{int(s):02d},{int(ms):03d}"

def create_srt_word_by_word(audio_path, text, output_file):
    words = text.strip().split()
    audio = AudioSegment.from_file(audio_path)
    duration_ms = len(audio)
    duration_per_word = duration_ms // len(words)

    with open(output_file, "w", encoding="utf-8") as f:
        for i, word in enumerate(words):
            start = i * duration_per_word
            end = (i + 1) * duration_per_word
            f.write(f"{i + 1}\n")
            f.write(f"{format_time_ms(start)} --> {format_time_ms(end)}\n")
            f.write(f"{word}\n\n")

# === Táº O VIDEO Tá»ª áº¢NH HOáº¶C VIDEO Ná»€N ===
def create_video_randomized_media(media_files, total_duration, change_every=5, word_count=0, output_file=TEMP_VIDEO):
    import random
    clips = []

    num_segments = max(1, word_count // change_every)
    duration_per_segment = total_duration / num_segments

    for _ in range(num_segments):
        file = random.choice(media_files)
        ext = os.path.splitext(file)[1].lower()
        if ext in [".jpg", ".png"]:
            clip = ImageClip(file, duration=duration_per_segment).resize(height=1920, width=1080)
        elif ext in [".mp4", ".mov"]:
            clip = VideoFileClip(file).subclip(0, duration_per_segment).resize(height=1920, width=1080)
        else:
            print(f"âš ï¸ Bá» qua file khÃ´ng há»— trá»£: {file}")
            continue
        clips.append(clip)

    final = concatenate_videoclips(clips, method="compose")
    final.write_videofile(output_file, fps=30)


# === GHÃ‰P VOICE + SUB VÃ€O VIDEO ===
def burn_sub_and_audio(video, srt, audio, output):
    command = [
        "ffmpeg", "-y",
        "-i", video,
        "-i", audio,
        "-filter_complex",
        f"[0:v]subtitles={srt}:force_style='Alignment=2,MarginV=40'[v]",
        "-map", "[v]",
        "-map", "1:a",
        "-c:v", "libx264",
        "-c:a", "aac",
        "-shortest",
        output
    ]
    subprocess.run(command)

# === MAIN ===
if __name__ == "__main__":
    print("ğŸ™ï¸ Táº O VIDEO SUB NHáº¢Y Tá»ªNG Tá»ª Vá»šI ELEVENLABS")
    folder = input("ğŸ“ Nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c áº£nh/video ná»n: ").strip('"')
    text = input("ğŸ“ Nháº­p ná»™i dung sub (text sáº½ Ä‘Æ°á»£c lá»“ng voice): ").strip()
    api_key = input("ğŸ” Nháº­p ElevenLabs API Key: ").strip()

    words = split_text_to_words(text)

    all_media = [
        os.path.join(folder, f)
        for f in os.listdir(folder)
        if f.lower().endswith((".jpg", ".png", ".mp4", ".mov"))
    ]

    if not all_media:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh/video!")
        exit()

    print("ğŸ¤ Táº¡o voice báº±ng ElevenLabs...")
    create_voice_with_elevenlabs(text, AUDIO_FILE, api_key)

    print("ğŸ“ Táº¡o phá»¥ Ä‘á» theo tá»«ng tá»«...")
    create_srt_word_by_word(AUDIO_FILE, text, SUB_FILE)

    audio_duration = AudioSegment.from_file(AUDIO_FILE).duration_seconds
    media = random.choices(all_media, k=1)  # DÃ¹ng 1 áº£nh/video ná»n

    print("ğŸ¬ Táº¡o video ná»n...")
    create_video_randomized_media(all_media, audio_duration, change_every=5, word_count=len(words), output_file=TEMP_VIDEO)

    print("ğŸ”¥ GhÃ©p sub vÃ  audio vÃ o video...")
    burn_sub_and_audio(TEMP_VIDEO, SUB_FILE, AUDIO_FILE, FINAL_VIDEO)

    print(f"âœ… ÄÃ£ táº¡o video hoÃ n chá»‰nh: {FINAL_VIDEO}")
